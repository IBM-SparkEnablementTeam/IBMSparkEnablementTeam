{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported Spark Modules\n",
      "Train data size is 494021\n",
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.mllib.clustering import KMeans\n",
    "    from pyspark.mllib.feature import StandardScaler\n",
    "    print (\"Successfully imported Spark Modules\")\n",
    "except ImportError as e:\n",
    "    print (\"Can not import Spark Modules\", e)\n",
    "    sys.exit(1)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Load 10 percent of train data\n",
    "import os.path\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('kddcup.data_10_percent_corrected')\n",
    "test_inputPath = os.path.join('kddcup_test.data')\n",
    "fileName = os.path.join(baseDir, inputPath)\n",
    "testFileName = os.path.join(baseDir, test_inputPath)\n",
    "# Load 10 percent of the entire KDD data set, from the Hadoop file share\n",
    "raw_data = sc.textFile(fileName)\n",
    "test_data = sc.textFile(testFileName)\n",
    "raw_data.take(5)\n",
    "\n",
    "print \"Train data size is {}\".format(raw_data.count())\n",
    "print \"Test data size is {}\".format(test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'smurf.', 280790)\n",
      "(u'neptune.', 107201)\n",
      "(u'normal.', 97278)\n",
      "(u'back.', 2203)\n",
      "(u'satan.', 1589)\n",
      "(u'ipsweep.', 1247)\n",
      "(u'portsweep.', 1040)\n",
      "(u'warezclient.', 1020)\n",
      "(u'teardrop.', 979)\n",
      "(u'pod.', 264)\n",
      "(u'nmap.', 231)\n",
      "(u'guess_passwd.', 53)\n",
      "(u'buffer_overflow.', 30)\n",
      "(u'land.', 21)\n",
      "(u'warezmaster.', 20)\n",
      "(u'imap.', 12)\n",
      "(u'rootkit.', 10)\n",
      "(u'loadmodule.', 9)\n",
      "(u'ftp_write.', 8)\n",
      "(u'multihop.', 7)\n",
      "(u'phf.', 4)\n",
      "(u'perl.', 3)\n",
      "(u'spy.', 2)\n",
      "('Counted in {} seconds', '7.548')\n"
     ]
    }
   ],
   "source": [
    "# Analyze the categorical features and display the distribution of \"labels\"\n",
    "\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from time import time\n",
    "from collections import OrderedDict\n",
    "#Counting all different labels\n",
    "protocol_type = raw_data.map(lambda line: line.strip().split(\",\")[1])\n",
    "services = raw_data.map(lambda line: line.strip().split(\",\")[2])\n",
    "labels = raw_data.map(lambda line: line.strip().split(\",\")[-1])\n",
    "\n",
    "t0 = time()\n",
    "protocol_counts = protocol_type.countByValue()\n",
    "services_counts = services.countByValue()\n",
    "labels_counts = labels.countByValue()\n",
    "tt = time()-t0\n",
    "\n",
    "protocol_sorted_labels = OrderedDict(sorted(protocol_counts.items(), key=lambda t: t[1], reverse=True))\n",
    "services_sorted_labels = OrderedDict(sorted(services_counts.items(), key=lambda t: t[1], reverse=True))\n",
    "labels_sorted_labels = OrderedDict(sorted(labels_counts.items(), key=lambda t: t[1], reverse=True))\n",
    "for label, count in labels_sorted_labels.items():\n",
    "    print(label, count)\n",
    "\n",
    "print(\"Counted in {} seconds\",format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To prepare categorical features 'protocol', 'service' and 'flag' for input to Decision Tree\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "# convert comma separated string to list of features\n",
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "test_csv_data = test_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "# Collect the different categories of the categorical features\n",
    "protocols = csv_data.map(lambda x: x[1]).distinct().collect()\n",
    "services = csv_data.map(lambda x: x[2]).distinct().collect()\n",
    "flags = csv_data.map(lambda x: x[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePointToLabelledPoint(point):\n",
    "    # Capture the features and omit the label\n",
    "    features = point[0:41]\n",
    "\n",
    "    # convert categorical variable 'protocol' to numeric  by replacing it with index of the collection of protocols\n",
    "    try: \n",
    "         features[1] = protocols.index(features[1])\n",
    "    except:\n",
    "         features[1] = len(protocols)\n",
    "\n",
    "    # convert categorical variable 'service' to numeric  variable by replacing it with index of the collection of services\n",
    "    try:\n",
    "        features[2] = services.index(features[2])\n",
    "    except:\n",
    "        features[2] = len(services)\n",
    "        # convert categorical variable 'flag' to numeric  variable by replacing it with index of the collection of flags\n",
    "    try:\n",
    "        features[3] = flags.index(features[3])\n",
    "    except:\n",
    "        features[3] = len(flags)\n",
    "\n",
    "    # Convert label to binary label, normal or attack\n",
    "    attack = 1.0\n",
    "    if point[41]=='normal.':\n",
    "        attack = 0.0\n",
    "    \n",
    "    # features = feature vector with categorical variables converted to numerical\n",
    "    # attack = label with binary classification\n",
    "    return LabeledPoint(attack, array([float(x) for x in features]))\n",
    "\n",
    "training_data = csv_data.map(parsePointToLabelledPoint)\n",
    "training_data.take(5)\n",
    "test_data = test_csv_data.map(parsePointToLabelledPoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier trained in {} seconds', '19.697')\n",
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 4 with 31 nodes\n",
      "  If (feature 22 <= 50.0)\n",
      "   If (feature 3 in {0.0,1.0,2.0,7.0,9.0,10.0})\n",
      "    If (feature 9 <= 1.0)\n",
      "     If (feature 36 <= 0.45)\n",
      "      Predict: 0.0\n",
      "     Else (feature 36 > 0.45)\n",
      "      Predict: 1.0\n",
      "    Else (feature 9 > 1.0)\n",
      "     If (feature 4 <= 1098.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 4 > 1098.0)\n",
      "      Predict: 1.0\n",
      "   Else (feature 3 not in {0.0,1.0,2.0,7.0,9.0,10.0})\n",
      "    If (feature 2 in {23.0,47.0,62.0})\n",
      "     If (feature 24 <= 0.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 24 > 0.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 2 not in {23.0,47.0,62.0})\n",
      "     If (feature 36 <= 0.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 36 > 0.0)\n",
      "      Predict: 1.0\n",
      "  Else (feature 22 > 50.0)\n",
      "   If (feature 5 <= 0.0)\n",
      "    If (feature 11 <= 0.0)\n",
      "     If (feature 2 in {21.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 2 not in {21.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 11 > 0.0)\n",
      "     If (feature 0 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 0.0)\n",
      "      Predict: 1.0\n",
      "   Else (feature 5 > 0.0)\n",
      "    If (feature 2 in {1.0,23.0,32.0,50.0,60.0})\n",
      "     If (feature 4 <= 7.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 4 > 7.0)\n",
      "      Predict: 0.0\n",
      "    Else (feature 2 not in {1.0,23.0,32.0,50.0,60.0})\n",
      "     If (feature 0 <= 342.0)\n",
      "      Predict: 1.0\n",
      "     Else (feature 0 > 342.0)\n",
      "      Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from time import time\n",
    "\n",
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(training_data, numClasses=2, \n",
    "                                          categoricalFeaturesInfo={1: len(protocols), 2: len(services), 3: len(flags)},\n",
    "                                          impurity='gini', maxDepth=4, maxBins=100)\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"Classifier trained in {} seconds\",format(round(tt,3)))\n",
    "\n",
    "print \"Learned classification tree model:\"\n",
    "print tree_model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, [10.0,5450.0,8.0]), LabeledPoint(0.0, [10.0,486.0,8.0]), LabeledPoint(0.0, [10.0,1337.0,8.0]), LabeledPoint(0.0, [10.0,1337.0,6.0]), LabeledPoint(0.0, [10.0,2032.0,6.0]), LabeledPoint(0.0, [10.0,2032.0,6.0]), LabeledPoint(0.0, [10.0,1940.0,1.0]), LabeledPoint(0.0, [10.0,4087.0,5.0]), LabeledPoint(0.0, [10.0,151.0,8.0]), LabeledPoint(0.0, [10.0,786.0,8.0])]\n"
     ]
    }
   ],
   "source": [
    "#Based on above structure of Decision Tree, \n",
    "# we conclude that features 22, 3 and 5 are the maximum entropy features\n",
    "# Hence we now extract only these 3 features\n",
    "def create_labeled_point_minimal(line_split):\n",
    "    # leave_out = [41]\n",
    "    clean_line_split = line_split[3:4] + line_split[5:6] + line_split[22:23]\n",
    "\n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[0] = flags.index(clean_line_split[0])\n",
    "    except:\n",
    "        clean_line_split[0] = len(flags)\n",
    "\n",
    "    # convert label to binary label\n",
    "    attack = 1.0\n",
    "    if line_split[41]=='normal.':\n",
    "        attack = 0.0\n",
    "\n",
    "    return LabeledPoint(attack, array([float(x) for x in clean_line_split]))\n",
    "\n",
    "training_data_minimal = csv_data.map(create_labeled_point_minimal)\n",
    "print(training_data_minimal.take(10))\n",
    "\n",
    "training_data_minimal.values().cache()\n",
    "test_data_minimal = test_csv_data.map(create_labeled_point_minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier trained in {} seconds', '9.2')\n",
      "Learned classification tree model with minimal fetures:\n",
      "DecisionTreeModel classifier of depth 3 with 15 nodes\n",
      "  If (feature 2 <= 87.0)\n",
      "   If (feature 0 in {0.0,1.0,2.0,7.0,9.0,10.0})\n",
      "    If (feature 1 <= 0.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 > 0.0)\n",
      "     Predict: 0.0\n",
      "   Else (feature 0 not in {0.0,1.0,2.0,7.0,9.0,10.0})\n",
      "    If (feature 1 <= 1644.0)\n",
      "     Predict: 1.0\n",
      "    Else (feature 1 > 1644.0)\n",
      "     Predict: 1.0\n",
      "  Else (feature 2 > 87.0)\n",
      "   If (feature 1 <= 0.0)\n",
      "    If (feature 2 <= 157.0)\n",
      "     Predict: 1.0\n",
      "    Else (feature 2 > 157.0)\n",
      "     Predict: 1.0\n",
      "   Else (feature 1 > 0.0)\n",
      "    If (feature 2 <= 509.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 2 > 509.0)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model_minimal = DecisionTree.trainClassifier(\n",
    "    training_data_minimal, numClasses=2, \n",
    "    categoricalFeaturesInfo={0: len(flags)},\n",
    "    impurity='gini', maxDepth=3, maxBins=32)\n",
    "tt = time() - t0\n",
    "\n",
    "print(\"Classifier trained in {} seconds\",format(round(tt,3)))\n",
    "\n",
    "print \"Learned classification tree model with minimal fetures:\"\n",
    "print tree_model_minimal.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 23.574 seconds. Test accuracy for decision tree  is 0.9208\n"
     ]
    }
   ],
   "source": [
    "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
    "labels_and_preds = test_data.map(lambda p: p.label).zip(predictions)\n",
    "\n",
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(lambda (v, p): v == p).count() / float(test_data.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Prediction made in {} seconds. Test accuracy for decision tree  is {}\".format(round(tt,3), round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 11.198 seconds. Test accuracy for minimal decision tree is 0.9167\n"
     ]
    }
   ],
   "source": [
    "predictions_minimal = tree_model_minimal.predict(test_data_minimal.map(lambda p: p.features))\n",
    "labels_and_preds_minimal = test_data_minimal.map(lambda p: p.label).zip(predictions_minimal)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "test_accuracy = labels_and_preds_minimal.filter(lambda (v, p): v == p).count() / float(test_data_minimal.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Prediction made in {} seconds. Test accuracy for minimal decision tree is {}\".format(round(tt,3), round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier trained in {} seconds', '26.166')\n"
     ]
    }
   ],
   "source": [
    "# Build the model using Logistic Regression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "t0 = time()\n",
    "logisticR_model = LogisticRegressionWithLBFGS.train(training_data)\n",
    "tt = time()-t0\n",
    "print(\"Classifier trained in {} seconds\",format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 26.118 seconds. Test accuracy for Logistic Regression model is 0.9193\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds_LogisticR = test_data.map(lambda p: (p.label, logisticR_model.predict(p.features)))\n",
    "logisticR_accuracy = labelsAndPreds_LogisticR.filter(lambda (v, p): v == p).count() / float(test_data.count())\n",
    "print \"Prediction made in {} seconds. Test accuracy for Logistic Regression model is {}\".format(round(tt,3), round(logisticR_accuracy,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Classifier SVM trained in {} seconds', '28.105')\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "t0 = time()\n",
    "SVM_model = SVMWithSGD.train(training_data, iterations=100)\n",
    "tt = time()-t0\n",
    "print(\"Classifier SVM trained in {} seconds\",format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 28.105 seconds. Test accuracy for SVM model is 0.8259\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds_SVM= test_data.map(lambda p: (p.label, SVM_model.predict(p.features)))\n",
    "SVM_accuracy = labelsAndPreds_SVM.filter(lambda (v, p): v == p).count() / float(test_data.count())\n",
    "print \"Prediction made in {} seconds. Test accuracy for SVM model is {}\".format(round(tt,3), round(SVM_accuracy,4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exctracting the anomalies out of the predictions made\n",
    "data_and_preds = test_data_minimal.zip(predictions_minimal)\n",
    "anomalies = data_and_preds.filter(lambda (v,p): p==1.0)\n",
    "print \"Number of Anomalies detected is\",anomalies.count()\n",
    "#anomalies.map(lambda (p): print \"Anomaly Detected for {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning initialized\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Timeout value connect was (10.0, 10.0), but it must be an int or float.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-439246f8938b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcolorsys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhsv_to_rgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mlgn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLightning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/lightning/main.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, local, ipython, auth, size)\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_basic_auth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not access server\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/lightning/main.pyc\u001b[0m in \u001b[0;36mcheck_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             r = requests.get(self.host + '/status', auth=self.auth,\n\u001b[1;32m--> 172\u001b[1;33m                              timeout=(10.0, 10.0))\n\u001b[0m\u001b[0;32m    173\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Problem connecting to server at %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         }\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeoutSauce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeoutSauce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/urllib3/util.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, connect, read, total)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_Default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_Default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'connect'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/urllib3/util.pyc\u001b[0m in \u001b[0;36m_validate_timeout\u001b[1;34m(cls, value, name)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             raise ValueError(\"Timeout value %s was %s, but it must be an \"\n\u001b[1;32m--> 147\u001b[1;33m                              \"int or float.\" % (name, value))\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Timeout value connect was (10.0, 10.0), but it must be an int or float."
     ]
    }
   ],
   "source": [
    "from lightning import Lightning\n",
    "from numpy import random, asarray, sqrt, arctan2, pi, clip\n",
    "from seaborn import color_palette\n",
    "#from sklearn import datasets\n",
    "from colorsys import hsv_to_rgb\n",
    "\n",
    "lgn = Lightning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#d, g = datasets.make_blobs(n_features=2, n_samples=200, centers=5, cluster_std=2.0, random_state=100)\n",
    "plot_data = (test_data_minimal.map(lambda p: (p.features))).collect()\n",
    "x = [(i[0]) for i in plot_data]\n",
    "y = [(i[1]) for i in plot_data]\n",
    "\n",
    "lgn.scatter(plot_data, group=test_data.label, alpha=0.8, size=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
